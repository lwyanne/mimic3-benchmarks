''' This module contains code to handle data '''

import os
import numpy as np
import scipy
import sys
from matplotlib import pyplot as plt
import pathlib
import pandas as pd
from json import JSONEncoder
import json
from tqdm import tqdm

class NumpyArrayEncoder(JSONEncoder):
    def default(self, obj):
        if isinstance(obj, np.ndarray):
            return obj.tolist()
        return JSONEncoder.default(self, obj)


def createDict(files):
    """create dict[covariates]->variableIndex
    """
    dic={}
    l=[]
    for file in files:
        with open(file) as f:
            content=f.readlines()
            for line in content:
                id=int(line.lstrip().rstrip())
                l.append(id)
            f.close()
        l=list(set(l))
    dic=dict(zip(l,list(range(len(l)))))
    return dic


class PatientHandler(object):
    """args
    ::task: 'mp' for Mortality prediction, 'sa' for survival analysis
    """
    def __init__(self,task='mp'):
        self.task=task
        self.dataPath=os.path.abspath(os.path.join(os.path.join(os.path.dirname(__file__), os.pardir),'data','root'))

    def gen_list(self, validStrategy='holdout',validrate=0.1):
        """This function is used to generate the list of patientIDs in training set, validation set, and test set
        """
        self.trainvalpath=os.path.join(self.dataPath,'train')
        self.testpath=os.path.join(self.dataPath,'test')
        trainval=[f for f in os.listdir(self.trainvalpath)] 
        self.len_trainval=len(trainval)
        self.trainFiles=trainval[:-int(self.len_trainval*validrate)]
        self.valFiles=trainval[int(self.len_trainval*validrate):]
        self.testFiles=[f for f in os.listdir(self.testpath)]

    def gen_data(self):
        """
        This function is used to generate 'vitals' for each patient in its own directory.
        The 'vitals' contains items that belong to Table `labevents` and Table `chartevents`
        The whole process was performed directly on the results 'event.csv' generated by the MIMIC-benchmark codes.
        """
        self.gen_list()
        with tqdm(total=100) as pbar:
            flag=0
            totallen=self.len_trainval+len(self.testFiles)
            for (filetype,filedir) in zip([self.trainFiles,self.valFiles,self.testFiles],[self.trainvalpath,self.trainvalpath,self.testpath]):
                for patient in filetype:
                    patientPath=os.path.join(filedir,patient)
                    if os.path.exists(os.path.join(patientPath,'vitals.npy')):
                        flag+=1
                        if flag%int((totallen/1000))==0:pbar.update(0.1)
                        continue
                    df=pd.read_csv(os.path.join(patientPath,'events.csv'))
                    nrow=df.shape[0]
                    timeorder=np.sort(df['CHARTTIME'].unique())
                    duation=len(timeorder)
                    timepoint=list(range(duation))
                    time_dic=dict(zip(timeorder,timepoint))
                    Df=np.zeros((duation,itemlen),dtype=object)
                    for i in range(nrow):

                        try:Df[time_dic[df.iloc[i,3]],item_dic[df.iloc[i,4]]]=df.iloc[i,5] #TODO: Check the valueom
                        except KeyError: continue
                    np.save(os.path.join(patientPath,'vitals'),Df)
                    flag+=1
                    if flag%int((totallen/1000))==0:pbar.update(0.1)
                    del Df,df


    def read_individual(self,patientPath):
        #





item_dic=createDict([os.path.abspath(os.path.join(os.path.join(os.path.dirname(__file__), os.pardir),'data','root','charteventsItems.csv')),
                    os.path.abspath(os.path.join(os.path.join(os.path.dirname(__file__), os.pardir),'data','root','labeventsItems.csv'))])   
itemlen=len(item_dic)
#item_dic[861]
#print(item_dic)
patientHandler=PatientHandler()

